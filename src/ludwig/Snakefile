"""Run ludwig

Example call:
snakemake --cores all --config symbol="MUX.DE" yaml="regression_return.yaml" -R experiment

Params:
    symbol: the stock symbol
    yaml: the name of yaml config file for ludwig
    run: (optional) run number, default: latest num in result directory 
    train_rule_active: (optional) set train rule active for downstream jobs, default: False

The yaml file follows convention {experiment_name}_{model_name}.yaml

Other examples:

```
snakemake --cores all --config symbol="MUX.DE" yaml="regression_return.yaml" -R experiment
```
- Will run a *new* experiment (train + evaluate) and store results in regression_return_{n+1}

```
snakemake --cores all --config symbol="MUX.DE" yaml="regression_return.yaml" train_rule_active="True"
```
- Will run a *new* training and store results in regression_return_{n+1}
- If you run the "evaluate" afterwards omitting train_rule_active param it will evaluate the test dataset againt the latest model, that is contained regression_return_{n+1}

```
snakemake --cores all --config symbol="MUX.DE" yaml="regression_return.yaml" -R predict
```
- Will run the predict rule on the lastest result

```
snakemake --cores all --config symbol="MUX.DE" yaml="regression_return.yaml" run="3" -R predict
```
- Will run the predict rule on the "regression_return_3" result

"""

##############################
# imports
##############################

import sys
import os
import pathlib
import re
import requests

# Some specific helper functions

from util import predict_csv_files
from util import url_avail
from util import last_run_result
from util import current_run_result

##############################
# Configuration
##############################

# config anchor
workdir: "/YASMaPE/src/ludwig"
configfile: "config.yaml"

# paths to image directories from config.yaml
DATA_ROOT_DIR = config["DATA_ROOT_DIR"]

# params from CLI
SYMBOL = str(config["symbol"]) if "symbol" in config is not None else sys.exit("No symbol provided. Use --config symbol=...")
YAML = str(config["yaml"]) if "yaml" in config is not None else sys.exit("No yaml config provided. Use --config yaml=...")
RUN = str(config["run"]) if "run" in config is not None else ""
TRAIN_RULE_ACTIVE = bool(config["train_rule_active"]) if "train_rule_active" in config is not None else False

# Directories
INPUT_DIR = os.path.join(DATA_ROOT_DIR, SYMBOL)
LUDWIG_DIR = os.path.join(INPUT_DIR, "ludwig")
LUDWIG_PREPROC_DIR = os.path.join(LUDWIG_DIR, "preprocess")
LUDWIG_YAML_FILE = os.path.join(LUDWIG_DIR, YAML)

# Files
TRAIN_DATASET = "train_set.parquet"
EVAL_DATASET = "eval_set.parquet"
PREPROC_TRAIN_SET = [ "train_set.training.hdf5", "train_set.meta.json" ]
PREPROC_EVAL_SET = [ "eval_set.test.hdf5" ]

# Names
# yaml file follows convention {experiment_name}_{model_name}.yaml
EXPERIMENT_NAME = re.search(r"(.+)_(.+)", YAML).group(1)
MODEL_NAME = re.search(r"(.+)_(.+).yaml$", YAML).group(2)

# Experiment dir
EXPERIMENT_OUTDIR = os.path.join(LUDWIG_DIR, EXPERIMENT_NAME)

# Result dirs
lrr = last_run_result(EXPERIMENT_OUTDIR)
LAST_RUN_RESULT = os.path.join(EXPERIMENT_OUTDIR, lrr)
CURRENT_RUN_RESULT = current_run_result(lrr, EXPERIMENT_OUTDIR, EXPERIMENT_NAME, MODEL_NAME)

# Compile model path 
# if RUN provided, use {EXPERIMENT_NAME}_{MODEL_NAME}_RUN
# else use output of last_run_result() and handle special cases
if not RUN:
    RUN_RESULT = lrr 
    if not RUN_RESULT:
        RUN_RESULT = os.path.join(EXPERIMENT_NAME + "_" + MODEL_NAME)
else:
    RUN_RESULT = os.path.join(EXPERIMENT_NAME + "_" + MODEL_NAME + "_" + RUN)

MODEL_PATH = os.path.join(EXPERIMENT_OUTDIR, RUN_RESULT, "model")

# other directories for ludwig processes
# - evaluate: TEST_OUTDIR
# - predict: PREDICT_OUTDIR
# - train: RUN_RESULT_DIR
TEST_OUTDIR = os.path.join(EXPERIMENT_OUTDIR, RUN_RESULT)
RUN_RESULT_DIR = PREDICT_OUTDIR = TEST_OUTDIR

# check for MLFLOW tracking server
MLFLOW_AVAIL = url_avail(url=os.getenv('MLFLOW_TRACKING_URI'))

##############################
# End of Configuration
##############################


##############################
# Rules start here
##############################

# a pseudo-rule that collects the target files
#rule all:
#    input: directory(LUDWIG_PREPROC_DIR)
#        [os.path.join(LUDWIG_PREPROC_DIR, f) for f in PREPROC_TRAIN_SET],
#        [os.path.join(LUDWIG_PREPROC_DIR, f) for f in PREPROC_EVAL_SET]


##############################
# Preprocessing
##############################

# runs ludwig preprocess on parquet file
rule preprocess:
    input:
        train = os.path.join(INPUT_DIR, TRAIN_DATASET),
        eval = os.path.join(INPUT_DIR, EVAL_DATASET),
    output: 
        # preprocessing output
        [os.path.join(INPUT_DIR, f) for f in PREPROC_TRAIN_SET],
        [os.path.join(INPUT_DIR, f) for f in PREPROC_EVAL_SET],
    shell:
        "cd {INPUT_DIR} && ludwig preprocess --training_set {input.train} --test_set {input.eval} -pc {LUDWIG_YAML_FILE}"


rule mv_preprocessed_file:
    input:
        # wire the preprocessing output to this rule's input
        rules.preprocess.output
    output:
        [os.path.join(LUDWIG_PREPROC_DIR, os.path.basename(f)) for f in rules.preprocess.output]
    shell:
        "mkdir -p {LUDWIG_PREPROC_DIR} && mv -t {LUDWIG_PREPROC_DIR} {input}"
        
##############################
# Training
##############################

# example call
# ludwig train --training_set .hdf5 --training_set_metadata .json 
# --output_directory regression --experiment_name regression 
# --model_name return --config xyz.yaml -ssl --mlflow

##
## Attn: this can be configured to be idempotent
##
## Set TRAIN_RULE_ACTIVE=False (default) to be for downstream rules idempotent
## typical downstream rules:
## * evaluate
## * predict
##
## Train a new model by explicitly run 'experiment' rule or set TRAIN_RULE_ACTIVE=True
## This would re-run upstream rules, if necessary.
##
## Note: keep default_target for this rule
##
rule train:
    default_target: True
    input:
        train_set = os.path.join(LUDWIG_PREPROC_DIR, PREPROC_TRAIN_SET[0]),
        train_meta = os.path.join(LUDWIG_PREPROC_DIR, PREPROC_TRAIN_SET[1]),
        config = LUDWIG_YAML_FILE,
    output:
        directory(CURRENT_RUN_RESULT) if TRAIN_RULE_ACTIVE else touch(os.path.join(RUN_RESULT_DIR, "training_statistics.json"))
    params:
        mlflow="--mlflow" if MLFLOW_AVAIL else "",
        ssl="--skip_save_log",
    shell:
        "test {TRAIN_RULE_ACTIVE} == 'True' && ( cd {LUDWIG_DIR} && ludwig train --training_set {input.train_set} --training_set_metadata {input.train_meta} --output_directory {EXPERIMENT_OUTDIR} --experiment_name {EXPERIMENT_NAME} --model_name {MODEL_NAME} --config {input.config} {params.ssl} {params.mlflow} ); exit 0"

##############################
# Experiment
##############################

# example call
# ludwig experiment --training_set .hdf5 --training_set_metadata .json --test_set .hdf5
# --output_directory regression --experiment_name regression 
# --model_name return --config xyz.yaml {params} --mlflow

## Attn: this is not idempotent ##
rule experiment:
    input:
        train_set = os.path.join(LUDWIG_PREPROC_DIR, PREPROC_TRAIN_SET[0]),
        train_meta = os.path.join(LUDWIG_PREPROC_DIR, PREPROC_TRAIN_SET[1]),
        eval_set = os.path.join(LUDWIG_PREPROC_DIR, PREPROC_EVAL_SET[0]),        
        config = LUDWIG_YAML_FILE,
    output: 
        directory(CURRENT_RUN_RESULT)
    params:
        mlflow="--mlflow" if MLFLOW_AVAIL else "",
        ssl="--skip_save_log",
        ssuo="--skip_save_unprocessed_output",        
        sstp="--skip_save_predictions",
    shell:
        "cd {LUDWIG_DIR} && ludwig experiment --training_set {input.train_set} --training_set_metadata {input.train_meta} --test_set {input.eval_set} --output_directory {EXPERIMENT_OUTDIR} --experiment_name {EXPERIMENT_NAME} --model_name {MODEL_NAME} --config {input.config} {params.ssl} {params.ssuo} {params.sstp} {params.mlflow}"


##############################
# Evaluate
##############################

# example call
# ludwig evaluate --dataset .hdf5 --output_directory regression_return_num 
# --model_path regression_return_num/model -scp --mlflow

rule evaluate:
    input:
        eval_set = os.path.join(LUDWIG_PREPROC_DIR, PREPROC_EVAL_SET[0]),
        model_path = MODEL_PATH,
    output: 
        # eval stats file
        os.path.join(TEST_OUTDIR, "test_statistics.json")
    params:
        mlflow="--mlflow" if MLFLOW_AVAIL else "",
        scp="--skip_collect_predictions"
    shell:
        "cd {LUDWIG_DIR} && ludwig evaluate --dataset {input.eval_set} --output_directory {TEST_OUTDIR} --model_path {input.model_path} {params.scp} {params.mlflow}"


##############################
# Predict
##############################

# example call
# ludwig predict --dataset .hdf5 --output_directory regression_return_num 
# --model_path regression_return_num/model 

rule predict:
    input:
        eval_set = os.path.join(LUDWIG_PREPROC_DIR, PREPROC_EVAL_SET[0]),
        model_path = MODEL_PATH,
    output: 
        # prediction files
        os.path.join(PREDICT_OUTDIR, "predictions.parquet"),
        os.path.join(PREDICT_OUTDIR, "predictions.shapes.json"),
        predict_csv_files(PREDICT_OUTDIR),
    params:
        mlflow="--mlflow" if MLFLOW_AVAIL else "",
        ssuo="--skip_save_unprocessed_output",
        sstp="--skip_save_predictions",
        predict_csv = predict_csv_files(PREDICT_OUTDIR),
    shell:
        "cd {LUDWIG_DIR} && ludwig predict --dataset {input.eval_set} --output_directory {PREDICT_OUTDIR} --model_path {input.model_path} {params.ssuo} {params.mlflow}"

rule predict_cleanup_csv:
    input:
        predict_csv_files(PREDICT_OUTDIR),
    shell:
        "rm -rf {input}"
        
